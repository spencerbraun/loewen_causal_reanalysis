---
title: "governing governing"
author: "Spencer Braun"
date: "11/12/2020"
output:
  pdf_document: default
  html_document: default
---




```{r, message=F}
library(DOS2)
library(optmatch)
library(RItools)
library(rcbalance)

library(readstata13)
library(tidyverse)
library(haven)

source("utility.R")
```


```{r, warning=FALSE, message=FALSE}
if (!require(hrbrthemes)) install.packages('hrbrthemes')
library(hrbrthemes)
theme_set(theme_ipsum())
```



## Main Analysis

Uses similar causal methods to causal_reanalysis.Rmd, but conditions on the governing party. The paper found a statistically signficant increase in the vote share for governing members with the power to propose. 
```{r}
main <- read.csv("processed_data/main.csv")
# main %>% head()
# main %>% names()


analysis.cols <- main %>% dplyr::select(p2p,
  current_vote,
  transfersshare,
  donationsshare,
  gov,
  y2006,
  female,
  exminister,
  previous_vote,
  media_mentions,
  quality,
  years_served
)  

covariates <- c(
  "transfersshare",
  "donationsshare",
  "y2006",
  "female",
  "exminister",
  "previous_vote",
  "media_mentions",
  "quality",
  "years_served"
)



# for now, drop NAs

analysis <- analysis.cols %>% 
  drop_na() %>%
  dplyr::rename(zb = p2p) %>%
  dplyr::rename(y = current_vote)



analysis.cols.large <- main %>% dplyr::select(
  p2p,
  current_vote,
  transfersshare,
  donationsshare,
  gov,
  y2006,
  female,
  exminister,
  previous_vote,
  media_mentions,
  quality,
  years_served,
  # province, #prov if need numeric
  election, 
  winner,
  pop_per_km2,
  immigrants,
  citizens,
  unemployment_rate,
  median_family_income
) 

analysis.large <- analysis.cols.large %>% 
  drop_na() %>%
  dplyr::rename(zb = p2p) %>%
  dplyr::rename(y = current_vote)

governing <- analysis %>% filter(gov == 1) %>% dplyr::select(-gov)
governing.large <- analysis.large %>% filter(gov == 1) %>% dplyr::select(-gov)

governing %>%
  group_by(zb) %>%
  summarise(count=n())

sapply(governing, function(x) sum(is.na(x)))
```


### Propensity Scores

```{r}
prop.scores <- glm(zb ~ . - y, family=binomial, data=governing)
governing$prop <- prop.scores$fitted.values


prop.scores.large <- glm(zb ~ . - y, family=binomial, data=governing.large)
governing.large$prop.large <- prop.scores.large$fitted.values


governing$prop.large <- prop.scores.large$fitted.values
```


Over lap much better for simple prop score
```{r}
prop.models <- governing %>% 
  select(zb, prop, prop.large) %>%
  pivot_longer(-zb, values_to="Value", names_to="PropScoreModel") %>%
  mutate(names = ifelse(PropScoreModel == "prop", "Model 1", "Model 2")) %>%
  ggplot() + 
  geom_density(aes(x=Value, fill=factor(zb)), alpha=0.3)  +
  facet_wrap(.~names) + 
  scale_x_continuous(limits=c(0,1)) + 
  labs(
    title="Propensity Distributions under Different Models",
    x="Propensity Score",
    fill="Treatment Group"
    )



```


```{r}
governing  %>% ggplot() + 
  geom_density(aes(x=prop.large, fill=factor(zb)), alpha=0.5) + 
  theme_bw()
```

### Matching

```{r}
plot(xBalance(zb ~ . - 1 -y -prop.large -prop, data=governing))
# plot(xBalance(zb ~ . - 1 -y, data=governing.large))
```


```{r, fig.height=11}
governing %>%
  dplyr::select(zb, covariates) %>%
  pivot_longer(-zb, names_to="covariate", values_to="value") %>%
  ggplot(aes(x = value, color = as.factor(zb), fill = as.factor(zb))) +
  geom_histogram(bins=30) +
  facet_grid(cols=vars(covariate), rows=vars(zb), scales='free_x')
```

```{r}
governing.large %>%
  ggplot(aes(x = previous_vote, color = as.factor(zb), fill = as.factor(zb))) +
  geom_histogram(bins=30) +
  facet_wrap(.~zb)
  
```


```{r}
governing %>%
  ggplot(aes(x = quality, color = as.factor(zb), fill = as.factor(zb))) +
  geom_histogram(bins=30) +
  facet_wrap(.~zb)
  
```

```{r}

names(governing)

governing %>%
  ggplot() + 
  geom_density(aes(x=prop, fill=factor(y2006)), alpha=0.5)
```



#### 1:1 Exact Matching

```{r}
z <- governing$zb
X <- governing %>% dplyr::select(-c(zb, prop, y, prop.large))

distance <- smahal(z, X) 
distance.cal <- addcaliper(distance, z=governing$zb, p=governing$prop, caliper=0.1)

governing %>%
  group_by(zb) %>%
  summarise(count=n())


matches <- pairmatch(distance, data=governing)
plot(xBalance(zb ~ . - 1 + strata(matches)  -prop.large -y, data=governing))

matches.cal <- pairmatch(distance.cal, data=governing)
matches.df <- summarize.match(governing, matches.cal)

plot(xBalance(zb ~ . + strata(matches.cal) - 1 - y -prop.large, data=governing))
```


I checked on the NAs in the matches - turns out these are just the extra control units. All treatment units are 1:1 matched with a control unit, so we should be 100% good here. 
```{r}
sum(is.na(matches)) 

sum(!is.na(matches))/2 ==  governing %>% summarise(sum(zb))


sum(is.na(matches.cal))
sum(!is.na(matches.cal))
```



```{r}

outcomes.unmatched <- governing %>%
  select(zb, y) %>%
  ggplot() + 
  geom_density(aes(x=y, fill=factor(zb)), alpha=0.3) + 
  scale_x_continuous(limits=c(0,100)) + 
  labs(x="Vote Share", title="Prematched Distribution", fill="Treatment Group")

outcomes.matched <- matches.df %>%
  select(y.1, y.0) %>%
  pivot_longer(c(y.1, y.0),names_to='Treatment', values_to='Values') %>%
  mutate(names = ifelse(Treatment == "y.1", 1, 0)) %>%
  ggplot() + 
  geom_density(aes(x=Values, fill=factor(names)), alpha=0.3) + 
  scale_x_continuous(limits=c(0,100)) + 
  labs(x="Vote Share", title="Matched Distribution", fill="Treatment Group") 
```

### FRT
```{r}

# DIM current assignment
T.obs1 <- matches.df %>%
  summarise(mean(y.1) - mean(y.0)) %>%
  pull(.)

T.obs1 


genPermute <- function(x, matches) {
  treated_unit <- sample(c(0,1), nrow(matches), replace=TRUE)
  matches %>%
    select(y.0, y.1) %>%
    mutate(treated=treated_unit) %>%
    mutate(treated_y = ifelse(treated == 1, y.1, y.0),
           control_y = ifelse(treated == 1, y.0, y.1)) %>%
    summarise(mean(treated_y) - mean(control_y)) %>%
    pull(.)
}

set.seed(123)
iters <- 1000
reps <- rep(NA,iters)

# Generate vector of test statistics under permutations
T.perms1 <- sapply(reps, function(x) genPermute(x, matches.df))
hist(T.perms1)
abline(v=T.obs1, col='red')


pval <- (1/iters) * (sum(ifelse(T.perms1 >=  T.obs1, 1, 0)) ) #calculate one sided p-value
pval 
```


Run sensitivity governing over all values of gamma needed. Uninteresting since it starts insignificant it only gets more so.
```{r}
senm.data1 <- cast.senm(governing, matches.cal)
sen.out <- sensitivitymult::senm(senm.data1$y, senm.data1$z, senm.data1$mset, gamma=1.2, trim = Inf, inner=0)

gamma.compute <- function(gamma) sensitivitymult::senm(senm.data1$y, senm.data1$z, senm.data1$mset, gamma=gamma, trim = Inf, inner=0)$pval
grange = seq(1,3,by=0.1)
sensitivity <- sapply(grange, gamma.compute)

gamma.plot <- data.frame(gamma=grange, pvalue=sensitivity) %>%
  ggplot(aes(x=gamma, y=sensitivity)) +
  geom_line() +
  geom_line(aes(x=seq(1,3,length=length(grange)), y=pval), col='navy', linetype='dashed') +
  geom_line(aes(x=seq(1,3,length=length(grange)), y=0.05), col='red', linetype='dotted') +
  labs(x="Odds Multiplier", y="Maximum P-Value")
```


### IPW Estimators

#### Horvitz Thompson

H-T and Hajek can be calculated directly, or seen as coefficients in a weight OLS. 
```{r}
horvitz.thompson <- governing %>%
  mutate(ZY1 = (zb * y)/prop) %>%
  mutate(ZY0 = ((1-zb) * y)/(1-prop)) %>%
  summarise(
    Units = n(),
    YBar1 = sum(ZY1) / nrow(governing),
    YBar0 = sum(ZY0) / nrow(governing),
    .groups='drop'
    ) %>%
  mutate(DIM=(YBar1 - YBar0)) %>%
  summarise(sum(DIM)) %>%
  pull(.)

horvitz.thompson


lambda <- governing %>%
  mutate(lambda = ifelse(zb == 1, 1/prop, 1/(1-prop))) %>%
  select(lambda) %>%
  pull(.)

ht.fit <- lm(y ~ zb, data=governing, weights=lambda)
summary(ht.fit)

```


#### Hajek

```{r}

hajek <- governing %>%
  mutate(ZY1 = (zb * y)/prop) %>%
  mutate(ZY0 = ((1-zb) * y)/(1-prop)) %>%
  summarise(
    Units = n(),
    YBar1 = sum(ZY1) / sum(zb / prop),
    YBar0 = sum(ZY0) / sum((1-zb)/(1-prop)),
    .groups='drop'
    ) %>%
  mutate(DIM=(YBar1 - YBar0)) %>%
  summarise(sum(DIM)) %>%
  pull(.)

hajek
denom1 <- (sum(governing$zb / governing$prop))
denom2<- (sum((1-governing$zb) / (1-governing$prop)))
lambda.hajek <- governing %>%
  mutate(lambda = (zb/prop)/denom1 + ((1-zb)/(1-prop))/denom2) %>%
  select(lambda) %>%
  pull(.)

lambda.hajek <- governing %>%
  mutate(lambda = zb/prop + (1-zb)/(1-prop)) %>%
  select(lambda) %>%
  pull(.)

hajek.fit <- lm(y ~ zb, data=governing, weights=lambda.hajek)
summary(hajek.fit)
```



### Subclassification with Neymanian CI's

```{r}
quant.vec <- quantile(governing$prop, c(0.2, 0.4, 0.6, 0.8))
```


```{r}
stratified <- governing %>%
  mutate(stratum = case_when(
    prop < quant.vec[1] ~ 1,
    (quant.vec[1] <= prop) & (prop < quant.vec[2]) ~ 2,
    (quant.vec[2] <= prop) & (prop < quant.vec[3]) ~ 3,
    (quant.vec[3] <= prop) & (prop < quant.vec[4]) ~ 4,
    prop >= quant.vec[4] ~ 5
  ))

# Number of units by stratum and treatment status
stratified %>% 
  group_by(stratum) %>%
  summarise(
    treated = sum(zb),
    control = sum(1-zb),
    .groups='drop'
    )

stratified %>%
  ggplot() + 
  geom_density(aes(x=prop, fill=factor(stratum)), alpha=0.4) +
  facet_wrap(vars(zb))
  
```


```{r}
stratified %>%
  mutate(ZY1 = zb * y) %>%
  mutate(ZY0 = (1-zb) * y) %>%
  group_by(stratum) %>%
  summarise(
    Units = n(),
    YBar1 = sum(ZY1) / sum(zb),
    YBar0 = sum(ZY0) / sum(1-zb),
    .groups='drop'
    ) %>%
  mutate(DIM=(YBar1 - YBar0))

```



```{r}
tau_k <- stratified %>%
  mutate(ZY1 = zb * y) %>%
  mutate(ZY0 = (1-zb) * y) %>%
  group_by(stratum) %>%
  summarise(
    Units = n(),
    YBar1 = sum(ZY1) / sum(zb),
    YBar0 = sum(ZY0) / sum(1-zb),
    .groups='drop'
    ) %>%
  mutate(DIM=(YBar1 - YBar0) * Units/nrow(stratified)) %>%
  summarise(sum(DIM)) %>%
  pull(.)

tau_k  


tau_k.var <- stratified %>%
  group_by(stratum, zb) %>%
  summarise(
    N = n(),
    Var = var(y), 
    .groups='drop'
    ) %>%
  mutate(weighted_V = Var / N) %>%
  group_by(stratum) %>%
  summarise(
    stratum_var = sum(weighted_V) * (sum(N) / nrow(stratified))^2,
    .groups='drop'
    ) %>%
  summarise(sum(stratum_var)) %>%
  pull(.)
  
tau_k.var
```


Compute a 95% confidence interval 
```{r}
normalCI <- function(tau, variance) {
  c(tau - sqrt(variance)*qnorm(.975), tau + sqrt(variance)*qnorm(.975))
}

normalCI(tau_k, tau_k.var)
```


Null result